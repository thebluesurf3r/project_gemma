{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'utils')))  # Adjust the path based on your structure\n",
    "from logging_configuration import setup_logging\n",
    "from load_from_csv import load_data\n",
    "from tabulate_style import tab_fmt\n",
    "from explode_tokens import explode_to_tokens\n",
    "from custom_plotly_template import get_custom_layout, set_custom_template\n",
    "\n",
    "# Call the function to set the custom template\n",
    "set_custom_template() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_token_sentiment(tokens_df, sentiment_types=['compound'], return_type='dataframe'):\n",
    "    \"\"\"\n",
    "    Analyzes sentiment for tokens in tokens_df using NLTK's VADER sentiment analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - tokens_df: DataFrame containing individual tokens in a 'paragraph' column.\n",
    "    - sentiment_types: list of str, sentiment scores to calculate, e.g., ['compound', 'pos'].\n",
    "    - return_type: str, 'dataframe', 'plot', or 'both' for output preference.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with sentiment scores or None based on return_type.\n",
    "    \"\"\"\n",
    "    # Ensure tokens_df has the correct structure\n",
    "    if 'paragraph' not in tokens_df.columns:\n",
    "        logging.error(\"The DataFrame must contain a 'paragraph' column.\")\n",
    "        return None\n",
    "\n",
    "    # Filter out non-alphabetic tokens and empty strings\n",
    "    tokens_df = tokens_df[tokens_df['paragraph'].str.isalpha() & tokens_df['paragraph'].str.strip().astype(bool)].copy()\n",
    "\n",
    "    # Calculate the length (character count) of each token\n",
    "    tokens_df['length'] = tokens_df['paragraph'].str.len()\n",
    "\n",
    "    # Initialize sentiment score columns\n",
    "    for sentiment_type in sentiment_types:\n",
    "        tokens_df[sentiment_type] = None  # Initialize columns\n",
    "\n",
    "    # Apply sentiment analysis to each token with error handling\n",
    "    for i, token in enumerate(tokens_df['paragraph']):\n",
    "        try:\n",
    "            scores = sia.polarity_scores(token)\n",
    "            for sentiment_type in sentiment_types:\n",
    "                tokens_df.at[i, sentiment_type] = scores[sentiment_type]\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculating sentiment for token index {i}: {e}\")\n",
    "            for sentiment_type in sentiment_types:\n",
    "                tokens_df.at[i, sentiment_type] = None\n",
    "\n",
    "    # Calculate the 95th percentile for each sentiment type and log the values\n",
    "    for sentiment_type in sentiment_types:\n",
    "        if sentiment_type in tokens_df.columns:\n",
    "            percentile_95_sentiment = round(tokens_df[sentiment_type].quantile(0.95), 2)\n",
    "            logging.info(f\"95th Percentile Sentiment Score ({sentiment_type}): {percentile_95_sentiment}\")\n",
    "\n",
    "            # Filter tokens with sentiment >= 95th percentile\n",
    "            high_sentiment_tokens = tokens_df[tokens_df[sentiment_type] >= percentile_95_sentiment]\n",
    "            logging.info(\"Top tokens by sentiment score:\\n\")\n",
    "            logging.info(high_sentiment_tokens.head())\n",
    "\n",
    "            # Plot sentiment distribution if required\n",
    "            if return_type in ['plot', 'both']:\n",
    "                fig = px.histogram(tokens_df, x=sentiment_type, nbins=30,\n",
    "                                   title=f'Distribution of {sentiment_type.capitalize()} Sentiment Scores',\n",
    "                                   labels={sentiment_type: 'Sentiment Score', 'count': 'Count'},\n",
    "                                   color_discrete_sequence=px.colors.sequential.Jet)  # Using 'Jet' color scale\n",
    "                fig.show()\n",
    "\n",
    "    return tokens_df if return_type in ['dataframe', 'both'] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 18:23:47,522 - INFO - cagliostro_gutenberg.csv imported successfully!\n",
      "2024-10-27 18:23:47,525 - INFO - There are 1775 rows and 8 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 18:23:47,556 - INFO - Schema of the loaded dataset:\n",
      "2024-10-27 18:23:47,565 - INFO - \n",
      "+----+---------------+-------------+------------+\n",
      "|    | Column Name   | Data Type   |   n_unique |\n",
      "|----+---------------+-------------+------------|\n",
      "|  0 | id            | int64       |       1775 |\n",
      "|  1 | chapter_title | object      |          1 |\n",
      "|  2 | paragraph     | object      |        908 |\n",
      "|  3 | quote         | float64     |          0 |\n",
      "|  4 | source_url    | object      |          1 |\n",
      "|  5 | created_at    | float64     |          0 |\n",
      "|  6 | title         | object      |          1 |\n",
      "|  7 | content       | float64     |          0 |\n",
      "+----+---------------+-------------+------------+\n",
      "2024-10-27 18:23:47,573 - WARNING - Column 'quote' has no unique values and will be dropped.\n",
      "2024-10-27 18:23:47,581 - WARNING - Column 'created_at' has no unique values and will be dropped.\n",
      "2024-10-27 18:23:47,587 - WARNING - Column 'content' has no unique values and will be dropped.\n"
     ]
    }
   ],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = explode_to_tokens(df, column='paragraph')\n",
    "tokens_df = pd.DataFrame(tokens_df)\n",
    "#tab_fmt(tokens_df, 5, style='psql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the analyze_token_sentiment function\n",
    "result = analyze_token_sentiment(tokens_df, sentiment_types=['compound', 'pos'], return_type='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_gemma-dF4c2h5V",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
