{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 13:41:36,608 - INFO - Logging initialized and set up successfully.\n",
      "2024-10-27 13:41:36,612 - INFO - Viewing the log: <function display_log_df at 0x7a608c0cb5b0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [timestamp, level, message]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "#=====================================================================================================================================================#\n",
    "#== Define a global DataFrame to store log entries ==#\n",
    "\n",
    "# This DataFrame will store all log entries, each consisting of a timestamp, logging level, and message.\n",
    "log_df = pd.DataFrame(columns=['timestamp', 'level', 'message'])\n",
    "\n",
    "#=====================================================================================================================================================#\n",
    "#== Define a custom logging handler that adds log records to a DataFrame ==#\n",
    "\n",
    "class DataFrameLoggingHandler(logging.Handler):\n",
    "    \"\"\"\n",
    "    A logging handler that appends log records to a DataFrame for in-memory logging.\n",
    "    Takes in a DataFrame and a queue to store log messages temporarily.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, queue):\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.queue = queue\n",
    "\n",
    "    def emit(self, record):\n",
    "        \"\"\"\n",
    "        Emit a log record to the DataFrame by pushing it to the queue.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Capture log details\n",
    "            timestamp = pd.Timestamp.now()\n",
    "            level = record.levelname\n",
    "            message = record.getMessage()\n",
    "            # Push to queue for processing\n",
    "            self.queue.put((timestamp, level, message))\n",
    "        except Exception:\n",
    "            self.handleError(record)  # Handle any unexpected errors during logging\n",
    "\n",
    "#=====================================================================================================================================================#\n",
    "#== Define a function to process the log queue and periodically clear the DataFrame ==#\n",
    "\n",
    "def process_log_queue(dataframe, queue, clear_interval=10):\n",
    "    \"\"\"\n",
    "    Continuously processes the log queue, adding entries to the DataFrame\n",
    "    and clearing the DataFrame at specified intervals.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Process each log entry from the queue\n",
    "        while not queue.empty():\n",
    "            timestamp, level, message = queue.get()\n",
    "            dataframe.loc[len(dataframe)] = [timestamp, level, message]\n",
    "\n",
    "        # Clear DataFrame contents after the specified interval\n",
    "        if len(dataframe) > 0:\n",
    "            dataframe.drop(dataframe.index, inplace=True)  # Clear DataFrame rows\n",
    "\n",
    "        # Sleep for the clear interval duration before the next check\n",
    "        time.sleep(clear_interval)\n",
    "\n",
    "#=====================================================================================================================================================#\n",
    "#== Set up logging to console, file, and DataFrame ==#\n",
    "\n",
    "def setup_logging(log_file='app_log.log', log_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configure logging to send output to a file, console, and DataFrame.\n",
    "    Returns a logger instance.\n",
    "    \"\"\"\n",
    "    # Clear any pre-existing handlers to avoid duplicate logs\n",
    "    logging.root.handlers.clear()\n",
    "\n",
    "    # Create a logger instance and set the logging level\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(log_level)\n",
    "\n",
    "    # Queue to hold log messages temporarily before processing\n",
    "    log_queue = Queue()\n",
    "\n",
    "    # Define handlers to output logs to various destinations\n",
    "    handlers = [\n",
    "        RotatingFileHandler(log_file, maxBytes=10485760, backupCount=5),  # File handler with 10 MB file rotation\n",
    "        logging.StreamHandler(),                                         # Console output handler\n",
    "        DataFrameLoggingHandler(log_df, log_queue)                       # Custom handler for DataFrame logging\n",
    "    ]\n",
    "    \n",
    "    # Set each handler's level and format, then add to the logger\n",
    "    for handler in handlers:\n",
    "        handler.setLevel(log_level)\n",
    "        handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "        logger.addHandler(handler)\n",
    "\n",
    "    # Start a background thread to process the log queue continuously\n",
    "    log_thread = Thread(target=process_log_queue, args=(log_df, log_queue), daemon=True)\n",
    "    log_thread.start()\n",
    "\n",
    "    return logger\n",
    "\n",
    "#=====================================================================================================================================================#\n",
    "#== Example Usage of Logger Setup ==#\n",
    "\n",
    "# Initialize logging configuration\n",
    "logger = setup_logging(log_file='app_log.log', log_level=logging.INFO)\n",
    "logger.info(\"Logging initialized and set up successfully.\")\n",
    "\n",
    "#=====================================================================================================================================================#\n",
    "#== Function to Display a Preview of the Log DataFrame ==#\n",
    "\n",
    "def display_log_df(log_df, rows=5, exclude_column=None):\n",
    "    \"\"\"\n",
    "    Display a preview of the log DataFrame, allowing an optional exclusion of a specified column.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Viewing the log: {display_log_df}\")\n",
    "    # Exclude specified column from view if present\n",
    "    if exclude_column in log_df.columns:\n",
    "        log_df = log_df.drop(columns=exclude_column)\n",
    "    return log_df.head(rows)\n",
    "\n",
    "#=====================================================================================================================================================#\n",
    "#== Example Preview of Logs in DataFrame ==#\n",
    "\n",
    "# Display the top 20 rows of the log DataFrame\n",
    "preview_log = display_log_df(log_df, rows=20)\n",
    "print(preview_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_gemma-dF4c2h5V",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
