{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/27 11:44:39 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/10/27 11:44:39 INFO SharedState: Warehouse path is 'file:/home/tron/git/project_gemma/utilities_ipynb/spark-warehouse'.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'apps')))\n",
    "from data_loader import load_data_spark\n",
    "\n",
    "from custom_plotly import set_custom_template\n",
    "set_custom_template()\n",
    "\n",
    "from keyword_analysis import analyze_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom layout parameters\n",
    "def get_custom_layout():\n",
    "    return {\n",
    "        \"plot_bgcolor\": \"black\",  # Set the background color to black\n",
    "        \"paper_bgcolor\": \"black\",  # Set the paper background color to black\n",
    "        \"font\": {\"family\": \"Arial\", \"size\": 14, \"color\": \"#FFFFFF\"},  # Font settings\n",
    "        \"title\": {\"x\": 0.5},  # Center-align title\n",
    "        \"margin\": {\"t\": 60, \"b\": 40, \"l\": 40, \"r\": 40},  # Tight layout margins\n",
    "        \"xaxis\": {\n",
    "            \"title_font\": {\"size\": 12},\n",
    "            \"tickfont\": {\"size\": 12},\n",
    "            \"showline\": True,  # Show the horizontal line\n",
    "            \"zeroline\": False,  # Hide the vertical line\n",
    "            \"gridcolor\": \"black\"  # Color of the grid lines\n",
    "        },\n",
    "        \"yaxis\": {\n",
    "            \"title_font\": {\"size\": 12},\n",
    "            \"tickfont\": {\"size\": 12},\n",
    "            \"showline\": True,  # Show the horizontal line\n",
    "            \"zeroline\": False,  # Hide the vertical line\n",
    "            \"gridcolor\": \"gray\"  # Color of the grid lines\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Set custom template based on 'plotly_dark' with updated layout\n",
    "custom_layout = {\n",
    "    \"layout\": get_custom_layout()\n",
    "}\n",
    "\n",
    "# Update the Plotly template\n",
    "pio.templates[\"custom_dark\"] = pio.templates[\"plotly_dark\"].update(custom_layout)\n",
    "pio.templates.default = \"custom_dark\"  # Use custom template as default\n",
    "pio.renderers.default = 'notebook'  # Render inline in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/27 11:44:44 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "2024-10-27 11:44:44,889 - ERROR - Error loading data: An error occurred while calling o29.jdbc.\n",
      ": java.lang.ClassNotFoundException: org.postgresql.Driver\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:103)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:103)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:103)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat org.apache.spark.sql.DataFrameReader.jdbc(DataFrameReader.scala:249)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "2024-10-27 11:44:44,891 - WARNING - Loaded DataFrame is empty or None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the path to the apps directory\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'apps')))  # Adjust the path based on your structure\n",
    "from data_loader import load_data_spark  # Now you can import your function\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set up environment variables for database connection\n",
    "os.environ['DB_USER'] = 'postgres'\n",
    "os.environ['DB_PASSWORD'] = 'password'\n",
    "os.environ['DB_HOST'] = 'localhost'\n",
    "os.environ['DB_PORT'] = '5432'\n",
    "os.environ['DB_NAME'] = 'project_gemma'\n",
    "\n",
    "\n",
    "\n",
    "# Add the path to the apps directory\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'apps')))  # Adjust the path based on your structure\n",
    "\n",
    "# Define the analyze_keywords function with fine-tuning sliders\n",
    "def analyze_keywords(keywords=None):\n",
    "    jdbc_url = 'jdbc:postgresql://localhost:5432/project_gemma'\n",
    "    table_name = 'cagliostro_gutenberg'\n",
    "    df = load_data_spark(jdbc_url, table_name)\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        logging.warning(\"Loaded DataFrame is empty or None.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Ensure 'paragraph' column exists\n",
    "    if 'paragraph' not in df.columns or df['paragraph'].isnull().all():\n",
    "        logging.error(\"'paragraph' column is missing or contains only NaN values.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Count occurrences of each keyword in the paragraphs\n",
    "    keyword_counts = {keyword: 0 for keyword in keywords} if keywords else {}\n",
    "    for paragraph in df['paragraph'].dropna():\n",
    "        for keyword in keywords:\n",
    "            keyword_counts[keyword] += paragraph.lower().count(keyword.lower())\n",
    "\n",
    "    # Convert counts to DataFrame and filter out zero-count keywords\n",
    "    keyword_counts_df = pd.DataFrame(keyword_counts.items(), columns=['keyword', 'count'])\n",
    "    keyword_counts_df = keyword_counts_df[keyword_counts_df['count'] > 0]\n",
    "\n",
    "    # Sort by count for consistent slider operation\n",
    "    keyword_counts_df = keyword_counts_df.sort_values(by='count').reset_index(drop=True)\n",
    "\n",
    "    # Create frames for each count threshold\n",
    "    max_count = int(keyword_counts_df['count'].max())\n",
    "    frames = []\n",
    "    for i in range(max_count + 1):\n",
    "        filtered_df = keyword_counts_df[keyword_counts_df['count'] <= i]\n",
    "        frames.append(go.Frame(\n",
    "            data=[go.Bar(\n",
    "                x=filtered_df['keyword'],\n",
    "                y=filtered_df['count'],\n",
    "                text=filtered_df['count'],\n",
    "                marker=dict(\n",
    "                    color=filtered_df['count'],\n",
    "                    coloraxis=\"coloraxis\"  # Link to the global color axis\n",
    "                )\n",
    "            )],\n",
    "            name=str(i)\n",
    "        ))\n",
    "\n",
    "    # Set up the initial figure\n",
    "    fig = go.Figure(\n",
    "        data=[go.Bar(\n",
    "            x=keyword_counts_df['keyword'],\n",
    "            y=keyword_counts_df['count'],\n",
    "            text=keyword_counts_df['count'],\n",
    "            marker=dict(\n",
    "                color=keyword_counts_df['count'],\n",
    "                coloraxis=\"coloraxis\"\n",
    "            )\n",
    "        )],\n",
    "        frames=frames\n",
    "    )\n",
    "\n",
    "    # Add a 'jet' color scale to the layout\n",
    "    fig.update_layout(\n",
    "        title=\"Keyword Frequency with Adjustable Count Threshold and Jet Color Scale\",\n",
    "        xaxis_title=\"Keyword\",\n",
    "        yaxis_title=\"Count\",\n",
    "        font=dict(family=\"Arial\", size=14, color=\"white\"),\n",
    "        plot_bgcolor=\"black\",\n",
    "        paper_bgcolor=\"black\",\n",
    "        coloraxis=dict(\n",
    "            colorscale=\"Jet\",  # Jet color scale for the color axis\n",
    "            colorbar=dict(title=\"Count\", tickvals=[0, max_count])\n",
    "        ),\n",
    "        sliders=[{\n",
    "            \"active\": max_count,\n",
    "            \"currentvalue\": {\"prefix\": \"Max Count Threshold: \", \"font\": {\"color\": \"white\", \"size\": 14}},\n",
    "            \"pad\": {\"t\": 50},\n",
    "            \"steps\": [\n",
    "                {\"method\": \"animate\", \"label\": str(i), \n",
    "                 \"args\": [[str(i)], {\"frame\": {\"duration\": 2000, \"redraw\": True}, \"mode\": \"immediate\", \"transition\": {\"duration\": 200, \"easing\": \"cubic-in-out\"}}]}\n",
    "                for i in range(max_count + 1)\n",
    "            ]\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
    "    fig.show()\n",
    "    logging.info(\"Keyword frequency analysis with native slider and jet color scale is complete.\")\n",
    "\n",
    "# Usage\n",
    "keywords = ['Cagliostro',\n",
    "            #'brother',\n",
    "            'son',\n",
    "            'father',\n",
    "            #'poor',\n",
    "            'die',\n",
    "            'rich',\n",
    "            'very']\n",
    "\n",
    "keyword_analysis = analyze_keywords(keywords)\n",
    "print(tabulate(keyword_analysis, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_gemma-dF4c2h5V",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
